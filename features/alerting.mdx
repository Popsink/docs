---
title: 'Popsink Alerting'
description: 'Native observability and alerting for your data pipelines'
icon: 'bell'
---

Popsink provides native observability through a custom Source Connector that streams the runtime activity of other Popsink connectors. This allows you to monitor connector health, failures, retries, and throughput in real time.

Using Popsink pipelines, you can apply alerting rules to this activity stream and route critical events to external systems via Target Connectors (Slack, Database, Webhooks, etc.).

<Note>
This creates a fully integrated alerting pipeline without requiring third-party monitoring systems.
</Note>

## Architecture

<CardGroup cols={2}>
  <Card title="Popsink Source Connector" icon="download">
    **Internal Activity Source**
    
    Captures events about Popsink connector activity:
    - Connector lifecycle events (started, stopped, failed)
    - Task health (heartbeat, lag, retries, errors)
    - Exposes them as a continuous event stream
  </Card>
  
  <Card title="Target Connectors" icon="upload">
    **Alert Forwarding**
    
    Forward alert events to external systems such as:
    - Slack channels
    - Databases for logging
    - Webhooks for custom integrations
    - Email notifications
  </Card>
</CardGroup>

## Use Cases

<AccordionGroup>
  <Accordion title="Connector Crash Detection" icon="circle-exclamation">
    Detect if a connector crashes or stops unexpectedly. Immediately notify your team through Slack or other channels to minimize downtime.
  </Accordion>
  
  <Accordion title="Error Rate Monitoring" icon="chart-line">
    Trigger alerts when error rates exceed predefined thresholds. Set up automated responses or escalation procedures for critical errors.
  </Accordion>
  
  <Accordion title="Performance Degradation" icon="gauge">
    Monitor throughput and latency metrics. Get notified when performance drops below acceptable levels.
  </Accordion>
  
  <Accordion title="Data Quality Issues" icon="shield-check">
    Track data validation failures and schema mismatches. Route data quality alerts to your data engineering team.
  </Accordion>
</AccordionGroup>

## How It Works

<Steps>
  <Step title="Enable Activity Monitoring">
    Configure the Popsink Source Connector to capture runtime activity from your connectors.
  </Step>
  
  <Step title="Define Alerting Rules">
    Set up filtering and transformation rules to identify critical events worth alerting on.
  </Step>
  
  <Step title="Configure Target Connectors">
    Connect to your preferred alerting destinations (Slack, webhooks, databases, etc.).
  </Step>
  
  <Step title="Test and Monitor">
    Verify your alerts are working correctly and adjust thresholds as needed.
  </Step>
</Steps>

## Example Alert Configurations

### Slack Integration

```yaml
source: popsink_activity
filters:
  - event_type: connector_failed
  - error_rate: > 5%
target: slack
destination:
  channel: "#data-alerts"
  mention: "@data-team"
```

### Database Logging

```yaml
source: popsink_activity
filters:
  - severity: warning, error, critical
target: postgres
destination:
  table: connector_logs
  schema: monitoring
```

### Webhook Alerting

```yaml
source: popsink_activity
filters:
  - connector_state: stopped
  - duration: > 5min
target: webhook
destination:
  url: https://your-system.com/alerts
  method: POST
```

## Benefits

<CardGroup cols={2}>
  <Card title="Real-Time Visibility" icon="eye">
    Get instant notifications about your pipeline health and issues as they occur.
  </Card>
  
  <Card title="No External Tools Required" icon="wrench">
    Built-in alerting means no need to integrate with external monitoring services.
  </Card>
  
  <Card title="Flexible Routing" icon="arrows-split-up-and-left">
    Send different types of alerts to different destinations based on severity and type.
  </Card>
  
  <Card title="Customizable Rules" icon="sliders">
    Define your own alerting logic with powerful filtering and transformation capabilities.
  </Card>
</CardGroup>

## Best Practices

<Tip>
**Start Simple:** Begin with basic connector failure alerts before building more complex monitoring rules.
</Tip>

<Tip>
**Avoid Alert Fatigue:** Set appropriate thresholds to avoid overwhelming your team with notifications.
</Tip>

<Tip>
**Test Regularly:** Periodically trigger test alerts to ensure your notification system is working correctly.
</Tip>

<Tip>
**Document Your Alerts:** Keep a clear record of what each alert means and what action should be taken.
</Tip>
